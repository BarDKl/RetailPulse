{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pathlib\n",
    "import pickle\n",
    "import plotly as px\n",
    "%matplotlib inline\n",
    "%xmode Verbose"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "database_url = \"postgresql://user:password@localhost:5432/retail_db\"\n",
    "engine = create_engine(database_url)\n",
    "# we split the dataset into training and test\n",
    "# to do this first we have to find the cutoff date which splits the time of our data in 70/30\n",
    "q_cutoff = \"\"\"\n",
    "WITH date_range AS (\n",
    "    SELECT MIN(invoicedate) as min_date, MAX(invoicedate) as max_date\n",
    "    FROM retail_db\n",
    "),\n",
    "duration AS (\n",
    "    SELECT max_date - min_date as total_days FROM date_range\n",
    ")\n",
    "SELECT\n",
    "    min_date + (total_days * 0.7) as cutoff_date\n",
    "FROM date_range, duration\n",
    "\"\"\"\n",
    "cutoff_date = pl.read_database(q_cutoff, engine)[0,0]\n",
    "print(f'cutoff_date: {cutoff_date}')\n",
    "# then we extract RFM data from the time before cutoff and tagret monetary value from the rest and merge them to have a labeled dataset\n",
    "rfm_data = pl.read_database(f\"\"\"\n",
    "    SELECT\n",
    "        customerid,\n",
    "        COUNT(invoiceno) as frequency,\n",
    "        EXTRACT(DAY FROM (DATE '{cutoff_date}' - MAX(invoicedate))) as recency,\n",
    "        SUM(quantity * unitprice) as monetary\n",
    "    FROM retail_db\n",
    "    WHERE customerid IS NOT NULL AND invoicedate <= '{cutoff_date}'\n",
    "    GROUP BY customerid\n",
    "\"\"\", engine)\n",
    "target_data = pl.read_database(f\"\"\"\n",
    "    SELECT\n",
    "        customerid,\n",
    "        SUM(quantity * unitprice) as target_monetary\n",
    "    FROM retail_db\n",
    "    WHERE customerid IS NOT NULL AND invoicedate > '{cutoff_date}'\n",
    "    GROUP BY customerid\n",
    "\"\"\", engine)\n",
    "# now we join the dataset and fill null values in targets with 0 (no record in target means that customer didn't spend anything after the cutoff so it is pretty logical)\n",
    "final_data = rfm_data.join(target_data, on='customerid', how='left').fill_null(0)\n",
    "print(final_data.describe())"
   ],
   "id": "f52ab29920e5929e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Now we split the data\n",
    "X = final_data.select(pl.col('frequency'),pl.col('recency'),pl.col('monetary')).to_numpy()\n",
    "Y = final_data.get_column('target_monetary').to_numpy()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ],
   "id": "ef85dfc72a4139bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Here is the process of selecting an amount of estimators - analysis showed that 200 will be best\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig.suptitle('Stability Check: Error Curves for Different Random Seeds', fontsize=16)\n",
    "\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "seeds = [0,4,8,12,16,20,24,28,32]\n",
    "\n",
    "estimator_options = [10, 50, 100, 200, 300]\n",
    "\n",
    "print(\"ðŸŒ² Running Stability Check (This might take a minute)...\")\n",
    "final_results = []\n",
    "for i, seed in enumerate(seeds):\n",
    "    ax = axes_flat[i]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in estimator_options:\n",
    "        model = RandomForestRegressor(n_estimators=n, random_state=seed, max_depth=5)\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_squared_error(Y_test, preds)\n",
    "        results.append(mae)\n",
    "\n",
    "    ax.plot(estimator_options, results, marker='o', linestyle='-', color='teal')\n",
    "    ax.set_title(f'Random Seed = {seed}')\n",
    "    ax.set_ylabel('MSE')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    final_results.append(results)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92) # Leave space for the big title\n",
    "plt.show()\n",
    "\n",
    "means = []\n",
    "final_results = np.array(final_results)\n",
    "for i in range(len(estimator_options)):\n",
    "    means.append([estimator_options[i],np.mean(final_results[i,:],axis=0)])\n"
   ],
   "id": "600b821cfb9c8428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Actual model\n",
    "print(min(means, key = lambda x : x[1]))\n",
    "final_model = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "final_model.fit(X, Y)\n"
   ],
   "id": "38d71ecc06e14184",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
