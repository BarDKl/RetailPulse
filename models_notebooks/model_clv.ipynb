{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T19:37:31.415999215Z",
     "start_time": "2026-01-19T19:37:31.375607156Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "%xmode Verbose"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T19:39:29.522588590Z",
     "start_time": "2026-01-19T19:39:29.138388443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "database_url = \"postgresql://user:password@localhost:5432/retail_db\"\n",
    "engine = create_engine(database_url)\n",
    "# we split the dataset into training and test\n",
    "# to do this first we have to find the cutoff date which splits the time of our data in 70/30\n",
    "q_cutoff = \"\"\"\n",
    "WITH date_range AS (\n",
    "    SELECT MIN(invoicedate) as min_date, MAX(invoicedate) as max_date\n",
    "    FROM retail_db\n",
    "),\n",
    "duration AS (\n",
    "    SELECT max_date - min_date as total_days FROM date_range\n",
    ")\n",
    "SELECT\n",
    "    min_date + (total_days * 0.7) as cutoff_date\n",
    "FROM date_range, duration\n",
    "\"\"\"\n",
    "cutoff_date = pl.read_database(q_cutoff, engine)[0,0]\n",
    "print(f'cutoff_date: {cutoff_date}')\n",
    "# then we extract RFM data from the time before cutoff and tagret monetary value from the rest and merge them to have a labeled dataset\n",
    "rfm_data = pl.read_database(f\"\"\"\n",
    "    SELECT\n",
    "        customerid,\n",
    "        COUNT(invoiceno) as frequency,\n",
    "        EXTRACT(DAY FROM (DATE '{cutoff_date}' - MAX(invoicedate))) as recency,\n",
    "        SUM(quantity * unitprice) as monetary\n",
    "    FROM retail_db\n",
    "    WHERE customerid IS NOT NULL AND invoicedate <= '{cutoff_date}'\n",
    "    GROUP BY customerid\n",
    "\"\"\", engine)\n",
    "target_data = pl.read_database(f\"\"\"\n",
    "    SELECT\n",
    "        customerid,\n",
    "        SUM(quantity * unitprice) as target_monetary\n",
    "    FROM retail_db\n",
    "    WHERE customerid IS NOT NULL AND invoicedate > '{cutoff_date}'\n",
    "    GROUP BY customerid\n",
    "\"\"\", engine)\n",
    "# now we join the dataset and fill null values in targets with 0 (no record in target means that customer didn't spend anything after the cutoff so it is pretty logical)\n",
    "final_data = rfm_data.join(target_data, on='customerid', how='left').fill_null(0)\n",
    "print(final_data.describe())"
   ],
   "id": "f52ab29920e5929e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutoff_date: 2011-08-19 13:54:48\n",
      "shape: (9, 6)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ statistic  â”† customerid   â”† frequency  â”† recency   â”† monetary    â”† target_monetary â”‚\n",
      "â”‚ ---        â”† ---          â”† ---        â”† ---       â”† ---         â”† ---             â”‚\n",
      "â”‚ str        â”† f64          â”† f64        â”† f64       â”† f64         â”† f64             â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ count      â”† 3258.0       â”† 3258.0     â”† 3258.0    â”† 3258.0      â”† 3258.0          â”‚\n",
      "â”‚ null_count â”† 0.0          â”† 0.0        â”† 0.0       â”† 0.0         â”† 0.0             â”‚\n",
      "â”‚ mean       â”† 15286.866483 â”† 66.5       â”† 86.452732 â”† 1547.710311 â”† 958.485231      â”‚\n",
      "â”‚ std        â”† 1726.057843  â”† 136.359868 â”† 73.45242  â”† 5888.215569 â”† 5215.745423     â”‚\n",
      "â”‚ min        â”† 12346.0      â”† 1.0        â”† 0.0       â”† 2.9         â”† 0.0             â”‚\n",
      "â”‚ 25%        â”† 13792.0      â”† 14.0       â”† 24.0      â”† 259.45      â”† 0.0             â”‚\n",
      "â”‚ 50%        â”† 15247.0      â”† 32.0       â”† 67.0      â”† 549.26      â”† 237.12          â”‚\n",
      "â”‚ 75%        â”† 16778.0      â”† 75.0       â”† 136.0     â”† 1313.98     â”† 814.96          â”‚\n",
      "â”‚ max        â”† 18287.0      â”† 3986.0     â”† 260.0     â”† 168503.1    â”† 168469.6        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T19:43:47.053846879Z",
     "start_time": "2026-01-19T19:43:47.037538104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we split the data\n",
    "X = final_data.select(pl.col('recency'),pl.col('frequency'),pl.col('monetary')).to_numpy()\n",
    "Y = final_data.get_column('target_monetary').to_numpy()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(\"First 5 rows of Training Data:\")\n",
    "print(X_train[:5])"
   ],
   "id": "ef85dfc72a4139bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of Training Data:\n",
      "[[254.    23.   165.94]\n",
      " [148.    16.   285.58]\n",
      " [217.    29.   689.95]\n",
      " [ 44.    22.   416.08]\n",
      " [ 13.    19.   376.55]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Here is the process of selecting an amount of estimators - analysis showed that 200 will be best\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "fig.suptitle('Stability Check: Error Curves for Different Random Seeds', fontsize=16)\n",
    "\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "seeds = [0,4,8,12,16,20,24,28,32]\n",
    "\n",
    "estimator_options = [10, 50, 100, 200, 300]\n",
    "\n",
    "print(\"ğŸŒ² Running Stability Check (This might take a minute)...\")\n",
    "final_results = []\n",
    "for i, seed in enumerate(seeds):\n",
    "    ax = axes_flat[i]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for n in estimator_options:\n",
    "        model = RandomForestRegressor(n_estimators=n, random_state=seed, max_depth=5)\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        mae = mean_squared_error(Y_test, preds)\n",
    "        results.append(mae)\n",
    "\n",
    "    ax.plot(estimator_options, results, marker='o', linestyle='-', color='teal')\n",
    "    ax.set_title(f'Random Seed = {seed}')\n",
    "    ax.set_ylabel('MSE')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    final_results.append(results)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92) # Leave space for the big title\n",
    "plt.show()\n",
    "\n",
    "means = []\n",
    "final_results = np.array(final_results)\n",
    "for i in range(len(estimator_options)):\n",
    "    means.append([estimator_options[i],np.mean(final_results[i,:],axis=0)])\n"
   ],
   "id": "600b821cfb9c8428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Actual model\n",
    "print(min(means, key = lambda x : x[1]))\n",
    "final_model = RandomForestRegressor(n_estimators=200, max_depth=5, random_state=42)\n",
    "final_model.fit(X, Y)\n"
   ],
   "id": "38d71ecc06e14184",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
